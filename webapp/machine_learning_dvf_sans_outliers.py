# -*- coding: utf-8 -*-
"""Machine Learning - DVF sans outliers

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NJfcj4mKktxJYQQKzhmYUHElow5SG1J6

# Machine Learning - DVF sans outliers
"""

#!pip install pycaret

#!pip install pandas-profiling[notebook,html]

"""### Importation des librairies"""

import pandas as pd
from pycaret.regression import *
from pandas_profiling import ProfileReport
from pycaret.utils import enable_colab
enable_colab()

"""### Importation du dataset"""

dvf=pd.read_csv("/content/drive/My Drive/data/dvf3.csv")
dvf.head()

"""### Remarques :
 *  Ce Dataframe comporte toutes les valeurs foncières, y compris les outliers.
 *  Pour faciliter les tests des algorithmes je crée un sample de 100000 entrées.
"""

dvf_sample= dvf.sample(n=100000,random_state=42).reset_index(drop=True)
dvf_sample.shape

profile = ProfileReport(dvf_sample, title='DVF without Outliers Profiling Report')
profile

profile.to_file(output_file="dvf_without_outliers_report.html")

"""### Séparation du dataframe en 2

Afin de démontrer la fonction Predict_model () sur des données invisibles, un échantillon de 5000 enregistrements a été retenu de l'ensemble de données d'origine pour être utilisé pour les prévisions. Cela ne doit pas être confondu avec une séparation train / test, car cette séparation particulière est effectuée pour simuler un scénario réel. Une autre façon de penser à cela est que ces 5000 enregistrements ne sont pas disponibles au moment où l'expérience d'apprentissage automatique a été effectuée.
"""

dfmodel= dvf_sample.sample(frac=0.95,random_state=42).reset_index(drop=True)
dfhide=dvf_sample.drop(dfmodel.index).reset_index(drop=True)
print("Shape du dfmodel: "+ str(dfmodel.shape))
print("Shape du dfhide: "+ str(dfhide.shape))

"""### Configuration du dataset

La fonction setup () initialise l'environnement dans pycaret et crée le pipeline de transformation pour préparer les données pour la modélisation et le déploiement. setup () doit être appelé avant d'exécuter toute autre fonction dans pycaret. Il prend deux paramètres obligatoires: une trame de données pandas et le nom de la colonne cible. Tous les autres paramètres sont facultatifs et sont utilisés pour personnaliser le pipeline de prétraitement.

1.   Data Scale
2.   Target transformation
"""

data=setup(data=dfmodel, target='valeur_fonciere', session_id=42, normalize = True, transformation = True, transform_target = True)

"""### Comparaison des différents algorithmes de régression

La fonction forme tous les modèles de la bibliothèque de modèles et les note à l'aide de la validation croisée kfold pour l'évaluation métrique. La sortie imprime une grille de score qui montre la moyenne des MAE, MSE, RMSE, R2, RMSLE et MAPE à travers les plis (10 par défaut) de tous les modèles disponibles dans la bibliothèque de modèles.
"""

compare_models()

"""### Création d'un modèle

Création du modèle Random Forest Regressor qui a un des meilleurs scores.
"""

rf=create_model('rf', fold = 5)
rf

"""### Tune model

Lorsqu'un modèle est créé à l'aide de la fonction create_model (), il utilise les hyperparamètres par défaut. Afin de régler les hyperparamètres, la fonction tune_model () est utilisée. Cette fonction règle automatiquement les hyperparamètres d'un modèle sur un espace de recherche prédéfini et le note à l'aide de la validation croisée kfold. La sortie imprime une grille de score qui montre MAE, MSE, RMSE, R2, RMSLE et MAPE par pli.
"""

tuned_rf = tune_model('rf', fold = 5, n_iter=5)

tuned_rf

"""### Visualisation du modèle

#### Residual Plot
"""

plot_model(rf)

"""#### Prediction Error Plot"""

plot_model(rf, plot = 'error')

"""#### Feature Importance Plot"""

plot_model(rf, plot='feature')

"""### Prédiction sur le Test


Avant de finaliser le modèle, il est conseillé d'effectuer une dernière vérification en prédisant l'ensemble de test et en examinant les mesures d'évaluation.
"""

predict_model(rf)

"""### Finalisation du modèle

La fonction finalize_model () ajuste le modèle sur l'ensemble de données complet, y compris l'échantillon test / hold-out (30% dans ce cas). Le but de cette fonction est de former le modèle sur l'ensemble de données complet avant son déploiement en production.
"""

final_rf = finalize_model(rf)
final_rf

predict_model(final_rf)

"""### Prédiction sur les données cachées"""

hide_predictions = predict_model(final_rf, data=dfhide)
hide_predictions.head()

"""### Sauvegarde du model"""

save_model(final_rf,'FinalRF')

import pickle

filename = 'finalized_rf_model.pkl'
pickle.dump(final_rf, open(filename, 'wb'))

